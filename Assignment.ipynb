{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaEHGkzSOaYV"
   },
   "source": [
    "\n",
    "# Assignment:\n",
    "\n",
    "We have been tasked with analyzing images of streets from different European cities for a smart-city related project. To start working, we have a dataset of images from three cities taken from inside a car driving through different points of each city. The complete dataset can be found [here](https://www.cityscapes-dataset.com). Along with the images, we have also been given text files where we can find the types of objects in each of them and their positions. For each image, we have a text file with one or more objects. We are informed that this information was extracted using [YOLOv5](https://docs.ultralytics.com). YOLO (*You Only Look Once*) is a powerful algorithm based on convolutional networks for real-time object detection in images or videos. \n",
    "\n",
    "In this task, you will work with these files to analyze the images and draw conclusions without having to look at each of the images. The data is in the file **dataset.tar.gz**. Where you will find the following folders:\n",
    "\n",
    "* **images**: Folder that contains all the images. Note that the name of the file shows the city and the date the photograph was taken.\n",
    "\n",
    "*  **labels**:  In this folder, you will find .txt files with the same base name as the corresponding image. In each file, there will be as many lines as objects found in the image. For each object, there are 6 columns with the following information:\n",
    "\n",
    "      * **object identifier**: between 0 and 80, which are the number of objects YOLO can detect (we give you a relationship between identifier and object type in another file explained below).\n",
    "                     \n",
    "      * **object coordinates $x^n_c$,$y^n_c$, $w^n$, $h^n$**: The position of the detected object is defined with the coordinates of the *bounding box*, which is the rectangle containing the object. This is defined by 4 coordinates: the central value *($x^n_c$,$y^n_c$)* and the width and height of the rectangle *($w^n$, $h^n$)*. YOLO gives these values normalized, so they will be between 0 and 1, the horizontal coordinates and the width are divided by the total width of the image while the vertical coordinates and the height of the rectangle are divided by the total height of the image:     \n",
    "     \n",
    "$$\n",
    "x^n_c = \\frac{x_c}{W}, y^n_c = \\frac{y_c}{H}\\\\\n",
    "w^n = \\frac{w}{W}, h^n = \\frac{h}{H}  \n",
    "$$\n",
    "      \n",
    "\n",
    " where x_c, y_c is the central value of the image in pixels, w and h are the width and height of the rectangle and W and H are the width and height of the image. We show it in the following diagram:\n",
    " \n",
    " \n",
    "                             ________________       \n",
    "                            |  _w_           | \n",
    "                            | |   |          |   * --> (x_c,y_c)\n",
    "                            | h * |          H\n",
    "                            | |___|          |\n",
    "                            |_______ W ______|\n",
    "                            \n",
    "                             \n",
    "                            \n",
    "                            \n",
    "*  **detection confidence**: In the last column, you'll find the probability given by the YOLO model that the position of the detected object is correct.\n",
    "\n",
    "```\n",
    "9 0.760986 0.140137 0.0229492 0.104492 0.285246\n",
    "58 0.960693 0.693359 0.0786133 0.210938 0.293333\n",
    "9 0.928955 0.0634766 0.0405273 0.0996094 0.332471\n",
    "9 0.908691 0.059082 0.0791016 0.114258 0.374223\n",
    "9 0.801514 0.254395 0.0336914 0.135742 0.390878\n",
    "9 0.887451 0.0537109 0.0395508 0.107422 0.554214\n",
    "9 0.243896 0.267578 0.0209961 0.109375 0.591291\n",
    "2 0.438232 0.438965 0.0541992 0.0478516 0.740896\n",
    "2 0.753662 0.459473 0.0825195 0.100586 0.745214\n",
    "2 0.530273 0.453613 0.0576172 0.0771484 0.814936\n",
    "2 0.384766 0.450195 0.0634766 0.107422 0.829835\n",
    "...\n",
    "```\n",
    "\n",
    "For example, in the first line of the file showed above, there's an object with an identifier equal to 9, with normalized coordinates: x_c=0.760986, y_c=0.140137, w=0.0229492 h=0.104492, and the probability that it is correctly detected is equal to 0.285246.\n",
    "\n",
    "\n",
    "\n",
    "* **class_name.txt**: In this file, you will find the relationship between the object identifier and the name. For example:\n",
    "\n",
    "````\n",
    "0 person\n",
    "1 bicycle\n",
    "2 car\n",
    "3 motorcycle\n",
    "4 airplane\n",
    "5 bus\n",
    "6 train\n",
    "7 truck\n",
    "....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySGU4MKlPi9_"
   },
   "source": [
    "#Â Results presentation:\n",
    "\n",
    "To make the delivery easier and more homogeneous, we ask you to organize the code in such a way that from the main file it returns all the answers that are requested in the PEC using functions that you will have to define in modules. For this, in each exercise, we will indicate the format that each answer should have. In this way, by executing python `main.py`, the entire PEC will be answered. If you consider that it is better to do it differently, you will have to document it very well in the README so that it can be executed without any problem. We remind you that in the README you also have to indicate how to run the tests and check their coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HmjDLEziV2n"
   },
   "source": [
    "# Data Set Control and Review: \n",
    "\n",
    "When we start working on a data analysis project, it's a good practice to make sure the data is correct. In other words, an initial exploratory analysis is necessary to detect errors or special cases and make decisions on how to approach them. Here we propose: \n",
    "\n",
    "#### Exercise 1. \n",
    "Read all the images and text files and merge them into a dataframe with the columns you find interesting to solve the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 1.2.\n",
    "In this case we have few images, but in a realistic case (e.g. traffic control cameras) you could have many frames to analyze. In the case of having millions of files or very heavy files, how would you do it? (It is not necessary to implement the solution, just justify it).\n",
    "\n",
    "Display on the screen the first rows of the dataframe and answer question 1.2 with a `print`. \n",
    " \n",
    "\n",
    "#### Exercise 2.\n",
    "Sometimes we come across corrupted data, both due to human errors and some bug in the code. To detect if there is an invalid file, create a check_yolo function that takes a text file as input and returns a boolean depending on whether it has the YOLO format or not. Check the number of columns and the characteristics of each one to know if it meets the format described in the statement.\n",
    "\n",
    "If you detect files with any incompatible line or value, you will remove them from the dataset and work without them for the rest of the assignment.\n",
    "\n",
    "Call the function from the main code and write on the screen the name of the files that do not follow the YOLO format or, in case, show a message that no incompatible file has been found.\n",
    "\n",
    "\n",
    "#### Exercise 3. \n",
    "\n",
    "It is also important to check that the predictions are correct, for example that the information in the file corresponds to the objects in the image. The easiest way is to visualize it. To do this, we will draw the bounding boxes of the objects on top of the image.\n",
    "\n",
    "For this exercise, you will need to make a change of coordinates, as the way of defining the rectangle in YOLO and in `patches.Rectangle` is different:\n",
    "    \n",
    " \n",
    "             YOLO  (unnormalized)                    patches.Rectangle\n",
    "                                                                       \n",
    "              +-----width-----+                      +-----width-----+  \n",
    "              |               |                      |               |\n",
    "           height     *       |                    height            |\n",
    "              |     (x,y)     |                      |               |\n",
    "              +---------------+                (x,y) *---------------+ \n",
    "\n",
    "Remember to \"denormalize\" the YOLO coordinates so that they are in pixel numbers (integer values). For this you will need the original size of the images, which is W = 2048 and H = 1024.\n",
    "\n",
    "Check that the bounding boxes are encompassing the objects with the first photo of each city (taking into account the lexicographical order).\n",
    "\n",
    "During the execution of the main code, present the visualization of these three images with the outlines of the detected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNswBDJzQ0A0"
   },
   "source": [
    "# Data Analysis:\n",
    "#### Exercise 4. \n",
    "In this part we will work with objects with a confidence greater than 0.4 and only with the files that have passed the candidate test for YOLO.\n",
    "  \n",
    "#### Exercise 4.1\n",
    "Find and graphically represent the distribution of objects throughout the dataset. That is, we want to know for each object how many are detected in total. Display on screen the identifiers and names of the 5 most common objects and how many times they appear. Show a bar graph with the total number of objects of each class.\n",
    "  \n",
    "  \n",
    "#### Exercise 4.2.\n",
    "What is the average number of objects (regardless of type) per image? Show on the screen the result explained and formatted.\n",
    "\n",
    "\n",
    " \n",
    "#### Exercise 4.3. \n",
    "We want to know which are the three most popular objects per image. To define the most popular objects per image, we ask you to follow the following steps:\n",
    "\n",
    "  a) Create a function that given a dataframe returns an ordered dictionary according to the popularity of the object. The keys of the dictionary will be the name or identifier of the object and as value the times it has been among the 3 most popular objects of an image.\n",
    "  \n",
    "  b) Show on the screen the three most popular objects that have been the most times popular in the images.\n",
    "  \n",
    "  c) Do the most popular objects per image coincide with those found in the dataset in 4.1? If not: Explain why this may happen. If so: Give an example where it might not be. ** Respond in a print** on the screen.\n",
    "\n",
    "\n",
    "----------   \n",
    "\n",
    "\n",
    "**Note**:\n",
    "1) Rules for choosing the most popular objects in an image:\n",
    "\n",
    "2) If there are **less than 3 different objects or exactly 3 objects**, we will take all those objects that appear.\n",
    "\n",
    "If there are **more than 3 different objects**:\n",
    "\n",
    "2.1) If the highest frequency appears in more than three objects, we will take all those objects as the most popular (in this case there can be more than three).\n",
    "\n",
    "*Example (4 cats, 4 dogs, 4 ducks, 4 rats, 1 pigeon) -> most popular objects: (cat, dog, duck, rat)*\n",
    "\n",
    "2.2) If there is no tie in popularity between the 3rd and 4th most popular object, we will take the 3 most frequent objects.\n",
    "\n",
    "*Example (5 cats, 4 dogs, 4 ducks, 2 rats, 1 pigeon) -> most popular objects: (cat, dog, duck)*\n",
    "\n",
    "2.3) If the popularity tie occurs between the 3rd and 4th most frequent objects, we will do the following:\n",
    "\n",
    "2.3.1) If the tie occurs between the third and fourth most frequent objects, we will take only the two most popular objects.\n",
    "\n",
    "*Example (4 cats, 4 dogs, 2 ducks, 2 rats, 1 pigeon) -> most popular objects: (cat, dog)*\n",
    "\n",
    "2.3.2) If the frequency tie also occurs between the second and third, we will take only the most popular object.\n",
    "\n",
    "*Example (4 cats, 2 dogs, 2 ducks, 2 rats, 1 pigeon) -> most popular objects: (cat)*\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "#### Exercise 5. \n",
    "Graphically represent and **show on the screen** the number of cars found per year for each city. **Represent in a single graph** the results of the three cities.\n",
    "\n",
    "\n",
    "#### Exercise 6.\n",
    "Design a function to identify the images that do not belong to the city of Zurich in the Zurich dataset in the most automated way possible. This is a free exercise, there is not a single way to approach it, and the ability to find the images and the creativity of the response will be valued. Reason the response and explain the reasons why you have done it this way. Show on the screen the names of the files of the intruding images and the motivation of the solution you propose.\n",
    "\n",
    "\n",
    "#### Exercise 7. \n",
    "Save all the information in a .csv file with the following columns: image name, number of cars, number of traffic lights, number of people, city, year, if it belongs to a city or not (if you have detected it in task 6). Show on the screen, properly formatted, the name of the generated file and where you have saved it."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1uc6Rcurf4_qlh6Q485-54Sfg6jcKXzwF",
     "timestamp": 1664790160357
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
